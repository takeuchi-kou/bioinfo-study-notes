# 改善算法

## 1. 泛化不佳，下一步？

假如我们已经完成了代价函数的最小化，得到了一组参数，但是发现这个模型在对于新的房价预测效果不佳，那么该怎么办呢？

其中一个方案是收集更多的训练样本，但是这个方法往往费时费力又没效果。

还有一个方法是，尝试更少的特征。正如之前讲过的，减少特征以防止过拟合。

另外，也有可能是现在的特征还不够，我们需要增加一些特征。

也可以增加多项式特征，例如平方项或者两个特征相乘。

又或者是增大或者减小正则化参数$\lambda$的值。

这些可能的方法，每一个都会耗费几个月的时间，如果我们随机选择一个进行尝试，那么成本将会很高。所以我们需要更高效的选择方法。

![image-20220210083254511](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220210083254511.png)



有一个比较好的办法是进行机器学习诊断。这是一种测试，运行后能够让我们了解算法在哪里出了问题，以及我们该尝试什么样的改进方法。

![image-20220210083510636](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220210083510636.png)

## 2. 评估假设

对于只有一个特征的函数来说，我们可以画出如下图的曲线取评估该假设是否过拟合，但是对于有非常多的特征的假设，这一办法行不通，我们需要另外一种评估假设函数的方法。

![image-20220210084751946](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220210084751946.png)

有一种办法是把我们的数据按照7:3的比例分成训练集和测试集，注意这里最好是随机选择数据作为训练集和测试集。

![image-20220210085244305](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220210085244305.png)

### 线性回归的训练/测试流程

先从70%的数据训练数据，即得到最小的代价函数；

再用30%的数据去计算拟合误差

![image-20220210085640005](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220210085640005.png)

### 逻辑回归的训练/测试流程

同样，先从70%的数据里面学习得到 参数$\theta$；

再用30%的数据得到测试误差，如下图

![image-20220210090014880](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220210090014880.png)

或者，我们还可以用一种叫0/1错误分类误差的方法定义测试误差：当分类错误的时候，计数+1，最后除以整个测试集的个数。

![image-20220210091402937](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220210091402937.png)

## 3. 模型选择和训练/验证/测试集

过拟合问题就是训练集本身得到的误差不足以估计模型在新样本上的误差。

![image-20220210091845354](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220210091845354.png)

### 模型选择

假设我们要从一到十次项中选择合适的项次，我们用d表示degree of polynomial。

d=1时，表示线性函数；d=10时，表示函数最高有10次。

我们要做的事情是先从十个模型中选择一个，拟合这个模型并估计这个拟合好的模型对于新样本的泛化能力：

先选择第一个模型；

最小化模型的训练误差，得到参数向量$\theta^{(1)}$；

选择第二个模型，用它拟合训练集，得到另一个参数向量$\theta^{(2)}$；

如此一直到第十个模型和$\theta^{(10)}$；

对这些所有模型求测试误差，求出$J_{test}(\theta^{(1)})$ 、$J_{test}(\theta^{(2)})$等等，求出他们在测试集的性能；

然后从这些模型中选择出最好的一个，也就是看哪个模型有最小的测试误差。

假设最后我们选择了五次多项式，但是如何评估这个模型的泛化能力？$J_{test}(\theta^{(5)})$并不足以给出它的准确评估结果，因为我们拟合了一个额外的参数d，也就是多项式的次数；然后我们用测试集拟合了参数d，也就是我们选择了一个能够最好地拟合测试集的参数d的值。因此，我们的参数$\theta^{(5)}$在测试集上的性能很可能是对泛化误差的乐观估计。

总结一句话，就是参数d已经在测试集上被使用过了，我们就是用测试集挑选出的这个参数d(也就是5次多项式)，所以再重复使用测试集就不好使了。

![image-20220210093408039](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220210093408039.png)

### 重新划分数据

为了解决上述问题，我们对数据集重新划分为训练集、交叉验证集(CV)、测试集，典型比例为60%、20%、20%。

![image-20220210093806219](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220210093806219.png)

在重新划分数据的基础上，我们可以把数据分成训练误差、交叉验证误差、测试误差。

![image-20220210093927934](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220210093927934.png)

### 重新选择模型

现在，我们要使用交叉验证集而非测试集去对模型进行选择。

首先选择第一种假设，最小化代价函数，得到对应的参数向量$\theta^1$,以此类推得到其他多项式的参数向量；

用交叉验证集来验证，计算出$J_{cv}(\theta^{(1)})$ 、$J_{cv}(\theta^{(2)})$看看这些假设模型在交叉验证集上的效果如何；

然后选择交叉验证误差最小的一组假设作为我们的模型，假设4次多项式的误差最小，我们选择4次的假设，这意味着我们的参数d=4；

最后用测试集衡量算法选出的模型的泛化误差

![image-20220210094525837](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220210094525837.png)

## 4. 诊断偏差和方差

 ### 方差和偏差

欠拟合-高偏差，过拟合-高方差

![image-20220210095503347](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220210095503347.png)

如果我们在一张图上画出训练误差和交叉验证误差随着参数d变化的曲线，则很有可能是下图这样的：测试误差随着d增加逐渐降低，但是验证误差是先降低再上升的(因为过拟合问题)

![image-20220210100234877](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220210100234877.png)

有了这张图，我们就可以判断我们的模型是存在高偏差还是高方差问题了：如果训练误差高，验证误差也高(如曲线左端)，那么我们的模型就存在高偏差，也就是欠拟合问题；如果验证误差远远高于训练误差（如曲线右端），那么模型就存在高方差，也就是过拟合问题。

![image-20220210101339656](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220210101339656.png)

## 5. 正则化和偏差、方差

### 线性回归的正则化

假如我们要对一个4次的多项式进行拟合，首先我们得到一个代价函数，第二项是正则化项；

当正则系数$\lambda$很大的时候，参数被训练得接近0，模型近似一条直线，此时处于欠拟合，有高偏差bias；

当正则系数很小，参数没有被调整，模型容易过拟合，有高方差variance；

只有当正则系数合适的时候，才能得到一个刚好的模型。

那么如何自动得到一个刚好的正则化参数值呢？

![image-20220211090224233](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220211090224233.png)

### 选择正则化系数

在之前训练模型的时候，我们把正则化项加入到目标函数，即代价函数中进行优化，但是现在我们在训练集、交叉验证集以及测试集中，都不考虑正则化项，只是使用误差的平方和作为代价函数

![image-20220211090514533](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220211090514533.png)

我们先选定一系列想试的正则化参数值，本例中以2倍为步长，一共12个；

然后把这些值带入测试集中对代价函数进行优化，这样会得到12个参数向量$\theta$；

然后把这12个参数向量带入交叉验证集中，求出12个代价函数的值，看哪个最小，假设在本例中，$\theta^{(5)}$使得代价函数最小；

把$\theta^{(5)}$带入测试集中验证这个模型对于新样本的泛化能力

![image-20220211093936793](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220211093936793.png)

这就是模型选择在选取正则化参数$\lambda$时的应用。

### 方差/偏差与参数$\lambda$

现在我们看看训练误差和交叉验证误差随着参数$\lambda$变化的曲线:

当$\lambda$很小的时候，我们几乎没有正则化，那么模型很大可能是过拟合的，此时模型对训练集拟合得非常好，因此训练集误差小，而由于过拟合问题，其泛化能力差，对交叉验证集拟合得不好，因此交叉验证误差大，此时对应的是高方差；

当$\lambda$很大的时候，所有参数都接近0，模型欠拟合，因此对交叉验证集和训练集数据拟合得都很差，此时为高偏差。

得到的曲线接近下图，虽然过于理想化，但是中间总有一个$\lambda$值是刚好合适的。

![image-20220211095051093](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220211095051093.png)

## 6. 学习曲线

学习曲线可以帮助我们诊断一个学习算法是处于高偏差还是高方差状态。

### 什么是学习曲线

假设我们有一个比较大的样本空间用于训练一个二次函数，但是我们限制自己训练模型所使用的样本的个数；

比如说，我们只使用一个样本去训练模型，那么我们得到的训练误差将会是0；一直到2个、3个样本，误差依然是0。并且可以预想，样本数越多，二次函数对训练集的拟合就会越不那么准确，于是就形成了下图左下角训练误差随着样本数量增大的曲线；

对于交叉验证误差来说，当样本数很小的时候，模型对新样本的泛化能力差，交叉验证误差也会很大，随着训练集样本数量的增加，模型的泛化能力增加，交叉验证误差会慢慢降低

![image-20220211101446721](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220211101446721.png)

### 高偏差情况下的学习曲线

 为了显示高偏差情况，我们用一条直线去拟合一组数据；

当训练集很小的时候，由于模型泛化能力差交叉验证误差会非常大，而训练误差会非常小因为数据很容易被拟合；

当训练集增大到一定程度的时候，我们将会找到对数据集拟合得最好的那条直线，此时交叉验证误差变小了但仍然很大，而训练误差变大了，因为直线是无法很好地拟合这组数据的；

当训练集继续增大的时候，交叉验证误差和训练误差都会呈现出平缓趋势，两者非常接近并且都很高(这就是高偏差学习曲线的特点)，这是因为模型已经稳定在“最佳直线”上面了。

所以最终，训练误差和交叉验证误差的学习曲线在高偏差环境下呈现如下形状。

这表示，如果训练模型正处于高偏差情况下，那么选用更多的训练集数据对于改善算法表现是没有用处的。

![image-20220211102509581](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220211102509581.png)

### 高方差情况下的学习曲线

为了显示高方差情况，我们用一个100次的函数来拟合数据，并且正则化参数非常小。

在样本量小的情况下，过拟合非常严重，所以此时训练误差极低，而交叉验证误差极高；

当样本量慢慢增加，过拟合显得没那么严重了(但依然是过拟合的)，此时训练误差有所增加，交叉验证误差有所下降，但是两者之间的gap依然非常大(这就是高方差情况下学习曲线的特点)；

在这种情况下，增大样本量似乎对于改善算法有所帮助

![image-20220211103328518](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220211103328518.png)

## 7. 决定接下来做什么

假设我们用正则化的线性回归去预测房价，但是预测结果不好，下一步我们该如何改善算法？

1. 收集更多的训练样本：适用于高方差；
2. 用更少的特征：适用于高方差；
3. 增加更多特征：适用于高偏差；
4. 增加多项式特征：适用于高偏差；
5. 增大正则化参数$\lambda$：适用于高方差
6. 减小正则化参数：适用于高偏差

![image-20220211105809953](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220211105809953.png)

### 模型选择

对于一个数据集，我们可以选择使用一个较小的简单神经网络，也可以选择使用一个复杂的多层或者单元数较多的神经网络。

当神经网络比较简单的时候，它包含更少的参数，因此更容易出现欠拟合问题，但是它的好处是比较便宜；

当神经网络包含许多层或者单元数很多的时候，由于参数多所以会出现过拟合，这时只需要用正则化解决问题即可

![image-20220211110307057](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220211110307057.png)