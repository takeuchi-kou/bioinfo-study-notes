# 获得准确的算法：误差分析和大量数据

## 1. 以垃圾邮件分类为例

我们给出垃圾邮件和非垃圾邮件的例子，垃圾邮件有时会故意拼错一些单词。

假设训练集中的邮件已经用0/1作为是否为垃圾邮件的标签，我们要通过监督学习的方法构造分类器，对邮箱中的其他邮件进行分类。

![image-20220211112705126](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220211112705126.png)

### 确定特征

我们先浏览一些邮件，找出一些经常出现在垃圾邮件或者非垃圾邮件中的特征单词，例如找出了100个单词，那么这100个单词的出现与否(1/0)就是我们的特征向量(100维)；

拿到一封新邮件，我们在这封邮件里找是否出现了这100个单词，然后按照顺序把每个单词有没有出现填入特征向量里，如下图

![image-20220211115637244](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220211115637244.png)

要注意的是，在实践中，我们通常会选择在训练集中出现最频繁的10000-50000个单词，而不是手动选择100个

### 获得高精度和低谬误的方法

1. 收集更多的数据；
2. 捕获更多的特征，例如邮件地址以及标题等；
3. 从邮件的正文构建更复杂的特征；
4. 构建更复杂的算法来检测垃圾邮件中的拼写错误 

![image-20220211122816185](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220211122816185.png)

## 2. 误差分析

### 开始新项目的步骤

当你开始着手一个新的机器学习项目的时候，应该做的事情：

1. 从一个很简单的算法开始，快速实现，并且在交叉验证集上进行测试；
2. 画出学习曲线，看是否需要更多的数据或者特征，避免“过早优化”问题，用实际问题指导我们的决策；
3. 误差分析：以垃圾邮件分类为例，手动查看在验证集里面被错误分类的那些邮件，看看有什么共同特征，以此为启发去设计新的特征来改进这个算法。

![image-20220212100556648](https://gitee.com/joy_thestraydog/typora1.0/raw/master/image-20220212100556648.png)

### 误差分析的例子

例如在交叉验证集中分类了500封邮件，其中100封被错误分类。我们应该手动检验这100个错误邮件，然后对他们分类。

比如说，其中12个制药公司邮件，4个卖假货的，53个钓鱼邮件，这说明我们的分类器对于钓鱼邮件的分类效果很差，于是我们应该想想用什么特征能够改进这个问题；

另外，看看这些邮件具有哪些共同特征，例如有5封存在故意的拼写错误，16封有奇怪的邮箱地址，32封有不寻常的标点(例如感叹号)，那么我们应该对识别标点符号增加一些特征

![image-20220212101305713](https://gitee.com/joy_thestraydog/typora1.0/raw/master/image-20220212101305713.png)

### 单一规则的数值评价指标

例如，我们如何决定要不要用词干提取的方法去判别邮件特征？词干提取有好处，也有坏处，好处是可根据词干合并特征，坏处是有可能误认(例如universe和university)。

最好的方法就是用一个数值去估计在算法用和不用词干提取的表现：例如把在**交叉验证类错误率**作为评估数值，在没有使用词干提取的情况下出现5%分类错误，而在有词干提取的时候仅有3%，那么使用词干提取就是一个好方法。

再比如，是否应该吧Mom和mom视作同一个单词。同样使用单一规则的数值评价指标，也即交叉验证错误率，能够让我们很迅速地判断出来到底应该怎么决策。像这样，数值评价能够让我们有了新的想法立刻能够以数值进行验证，这回大大加速我们改善算法的进程  。

![image-20220212102502231](https://gitee.com/joy_thestraydog/typora1.0/raw/master/image-20220212102502231.png)

## 3. skewed classes

### 例子

假设我们用一个逻辑回归模型预测癌症是否为恶性(y=1时为恶性)，这个模型在测试集上的错误率是1%，也就是诊断的正确率是99%。

但是在我们的样本中，仅有0.5%的患者是恶性的。在这个时候，如果我们每次都把患者预测为良性，那么正确率就会高达99.5%，比我们的学习算法还高！

像这种一个类别比另一个类别的数量多得非常多的类别就是偏斜类skewed classes。

在偏斜类中，我们用之前的错误率并不能很好地度量算法精度的改善(例如从99.2%提升至99.5%)，我们需要一种新的衡量方法。

### precision/recall 查准率/召回率

还是以肿瘤预测为例，我们用一个混淆矩阵表示预测结果与真实结果。

**查准率precision**就是在所有被预测为肿瘤的患者中，真正患有肿瘤的比例，也就是 真阳性/预测阳性=真阳性/(真阳性+假阳性)。

**召回率recall**就是在所有确实患有肿瘤的患者中，多大比例是我们预测为患有肿瘤的？也就是真阳性/真正阳性=真阳性/(真阳性+假阴性)

![image-20220212150238065](https://gitee.com/joy_thestraydog/typora1.0/raw/master/image-20220212150238065.png)

在这种度量方法下，一个只会把患者预测为阴性的方法，其召回率将是0，因为它不会产生任何true positive结果，只有拥有高查准率和召回率的算法才是一个好的模型。

## 4. 查准率和召回率的平衡

依然以癌症诊断为例。

假如我们希望在十分确信的时候才告诉患者患有肿瘤，因为我们不想对太多的假阳性的患者进行无效治疗，此时我们可以把分类阈值从0.5调整到0.7，或者0.9，只有高度确信患有肿瘤的才会被告知，其他都被判定为良性。这样一来，这个分类结果的查准率会非常高，因为假阳性变少了，但召回率将会很低，因为假阴性变多了。

另一种情况，我们希望不漏掉太多患有肿瘤的人，因为漏诊会造成严重后果。此时我们可以把分类阈值调低至0.3，这样我们会判定更多有可能患有肿瘤的患者为阳性。这个分类结果的召回率将会非常高，因为假阴性 变少了，然而查准率将会变低，因为假阳性变多了。

所以，我们经常需要权衡查准率和召回率。

![image-20220212152452725](https://gitee.com/joy_thestraydog/typora1.0/raw/master/image-20220212152452725.png)

查准率和召回率曲线可能呈现多种不同的形状，这取决于回归模型的具体算法。

那么，我们该如何基于查准率和召回率选择不同的模型呢？

### $F_1 score$

有一种比较方法叫做F score，公式如下图。它赋予查准率和召回率中较低的值以较高的权重，也就是不允许任何一个值过低。这样有效防止了之前那种只会把病人分入阴性类别的算法获得较高的分数。如果想得到一个高分，那么查准率和召回率都要接近1才可以。

![image-20220212153734577](https://gitee.com/joy_thestraydog/typora1.0/raw/master/image-20220212153734577.png)

根据F值，我们可以轻松地判断哪个模型或者哪个阈值更好。

## 5. 数据量和算法

四种不同的算法精确度与训练集大小的关系：

随着数据集的增大，算法性能对应地增强了。、

很多研究都表明，能够增强算法精度的就是给予它大量的训练数据。

![image-20220213093312160](https://gitee.com/joy_thestraydog/typora1.0/raw/master/image-20220213093312160.png)

### 特征是否提供了用于预测的足够信息

- 提供了足够信息：

  for breakfast I ate ____ eggs

  我们知道这里面要填入的是two，而非too 或者to

- 没有提供足够信息

  例如预测房价，而只知道房子大小，不知道具体位、楼层等等，这样就很难准确预测。

一个很有用的用于检验特征是否足够的方法：一个人类专家是否能够根据这些特征作出准确预测？

![image-20220213121643874](https://gitee.com/joy_thestraydog/typora1.0/raw/master/image-20220213121643874.png)

当特征足够的时候，用大量数据去训练算法才是有用的。

### 大量数据的好处

假设特征值足够我们来准确预测结果y，并且我们使用的算法有非常多的参数(有非常多特征值的逻辑或者线性回归，或者有很多隐藏单元的机神经网络)，这些参数可以拟合非常复杂的函数，我们就可以认为我们使用的这个算法是一个低偏差算法(low bias algorithm)：因为这个算法可以拟合的函数非常复杂，复杂的函数倾向于低偏差，高方差。所以，我们可以认为这个算法得到的训练误差是很小的，也就是与训练集拟合的非常好。

假设我们又使用了一个非常非常大的训练集，所以尽管我们的参数很多，但是训练数据更多，所以我们的模型也并没有过拟合，也就是训练误差与测试误差是相似的。

又因为训练误差很小，所以测试误差也会很小。

另一种视角是，大量特征参数确保了低偏差，大量的训练数据确保了低方差。所以这两种方法结合后，我们就可以得到低偏差和低方差的学习算法。

![image-20220213122933907](https://gitee.com/joy_thestraydog/typora1.0/raw/master/image-20220213122933907.png)