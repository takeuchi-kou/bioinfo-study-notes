# Anomaly detection 异常检测

## 1. 问题动机

### 一个例子

假如我们正在检测飞机引擎，我们检测每个引擎的2个特征：

x1：产热量

x2：震动强度

当我们将已经经过检测的正常引擎的这两个特征画在图上，那么就会显示为下方散点图红×的分布样式。

这时有一个新的待检测引擎，我们按照其特征把它表示在这个图中，用绿×标识。

如果这个绿×与之前红×的分布位置相似，那么我们可以判断它可能是正常引擎；

如果绿×与红×离得非常远，那么这个新引擎可能就是一个anomaly(异常)。

![image-20220311185836827](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220311185836827.png)

### 正式一点的定义

我们有一个数据集$x^{(1)} \cdots x^{(m)}$,该数据集中的点都是正常的点。根据数据集的点的特征分布对其分布概率进行建模，得到模型p(x) *(以左下角这个图为例，p(x)告诉我们的是，一个正常的点分布在某个具体位置的概率有多大)*。

把待检测数据点$x_{test}$代入模型，得到一个概率$p(x_{test})$：

如果$p(x_{test})<\epsilon$，则这个点是一个异常点；

相反，如果$p(x_{test})>\epsilon$，则这个点是ok的。

![image-20220311190632343](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220311190632343.png)

### 异常检测的应用

购物网站欺诈行为的检测：有无异常用户行为；

制造业检测(例如飞机引擎)；

计算机集群管理：某一计算机是否存在异常

![image-20220311191446361](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220311191446361.png)

## 2. 复习高斯分布

### 定义

高斯分布即正态分布。

由两个参数控制：$\mu 和 \sigma$;

写作：$x \sim N(\mu,\sigma^2) $

其中$\mu$为平均值，控制钟形曲线在x轴上的位置；

$\sigma$是标准差，$\sigma^2$是方差，控制钟形曲线的宽度。

![image-20220311192717269](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220311192717269.png)

### 改变参数

高斯分布曲线下的面积总是等于1(因为高斯分布是一种概率分布)，

所以当$\sigma$从1变为0.5的时候，曲线宽度为原先的一半，而高度为原先的2倍；

当当$\sigma$​从1变为2的时候，曲线宽度为原先的两倍，而高度为原先的一半。

改变$\mu$则是把曲线在x轴上平移。

![image-20220311193313513](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220311193313513.png)

### 参数估计

如果我们有一个很像是高斯分布的数据集，想对这个高斯分布的参数做一个近似估计，那么我们可以从求$\mu$开始。

$\mu$就是所有数据的平均值；而已知平均值的情况下，可以求出数据集的方差$\sigma^2$；

把这两个数代入公式，就可以得到一个高斯分布。

这里参数估计的方法运用了极大似然估计法。

![image-20220311193913266](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220311193913266.png)

## 3. 算法

 ### 密度估计

假设我们有数据集$x^{(1)} \cdots x^{(m)}$，共m个数据；

其中每一个x都服从高斯分布：$x_j \sim N(\mu_j,\sigma_j^2)$

那么这个数据集的概率密度就是n个特征的概率密度的累乘: $p(x)=\prod p(x_j;\mu_j,\sigma_j^2)$

![image-20220313215147497](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220313215147497.png)

### 异常检测算法

第一步：选择能够代表example的异常状态的特征值$x_i$，这里有n个特征值;

第二步：找出这些数据的特征值的参数(假设特征值全部服从高斯分布，这里也就是找出它们的期望值以及方差)。这里可以用向量化的方式进行思考，即把原数据看做是一个向量，那么它们的期望和方差也都是一个向量。因为数据集中有m个数据点，所以共有m个n维向量

第三步：在使用累乘的方法的到数据集的概率密度估计后，将新的x代入这个概率模型，如果得到的p(x)小于某个极小值$\epsilon$，则这个新数据点被标注为一个异常。

![image-20220313220941696](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220313220941696.png)

### 异常检测算法的例子

首先我们把联合概率分布画出来，由于两个边缘概率都是正态分布，所以整体的联合概率分布也是一个二维的正态分布。

假定我们设$\epsilon=0.02$，那么当我们有一个新数据，带进联合概率密度函数中，得到的值大于0.02，就不是异常值；如果得到的值小于0.02，则标记为异常值。

在二维概率分布图中，异常检测可以想象成是一个高度为$\epsilon$的横截面，在等高线中间的位正常值，而在外边的就是异常值。

![image-20220313222001026](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220313222001026.png)

## 4. 异常检测的应用

### 用实数评估算法

我们知道，在建立一个学习算法时，如果我们能够用一个实数去评估算法，那么将会更容易做出决定。

假设我们有一些有标签的数据，其中大部分是正常的，混入了少量异常数据。

然后构建一个无标签的训练集，训练集中是正常值（允许混入异常值，但是我们要假设他们都是正常的）；

在交叉验证集与测试集中，数据都是有标签的，显示了该数据是否为异常值(y=1为异常)

![image-20220315135300546](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220315135300546.png)

### 以飞机引擎为例

假设有10000个好的引擎，有20个缺陷引擎(异常)。

我们挑出6000个好的引擎，放进训练集中；

假设每个引擎的参数都服从高斯分布，那么这些好引擎的概率模型可以通过上一节的联合概率密度公式算出：$p(x)=\prod p(x_j;\mu_j,\sigma_j^2)$

2000个正常引擎，10个异常引擎放进交叉验证集中；

再把2000个正常引擎，10个异常引擎放进测试集中。

- 坏的分配方式

  有的人会把同样的4000个引擎放进CV集合Test集中，但这是一种非常不好的做法。

![image-20220315154052906](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220315154052906.png)

### 算法评估

首先将模型p(x)拟合训练集$x^{(1)} \cdots x^{(m)}$；

在交叉验证集中检验x是否为异常：$p(x)<\epsilon$时为异常；$p(x)>\epsilon$​为正常。

由于我们的数据中，y=0占了绝大多数，所以分类正确率并不能很好地评估算法；

基于预测结果，我们可以得到这个算法的evaluation metrics：真阳性、假阳性、真阴性、假阴性，计算出算法的精度和召回率，以及$F_1-score$​。这样一来，就可以评估异常检测算法在CV和test集中的表现了。

另外，我们还可以通过cv集选择一个合适的$\epsilon$​（可以使精度和召回率好一点）。

cv集的作用是选择合适的特征和$\epsilon$，然后用test集进行最后的评估。

![image-20220315154630360](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220315154630360.png)

## 5. 异常检测 vs. 监督学习

既然异常检测是需要带标签的数据的，那么它与监督学习有什么不同呢？

- 当绝大多数都是标签都是negative，而positive极其少的时候，使用异常检测算法，用绝大多数的阴性数据拟合出p(x)的模型；而当正负样本数量都比较多的时候，使用监督学习。

- 异常的数量少，而种类多的时候，我们需要使用异常检测算法；例如飞机引擎故障会有非常多的种类，可能之后出现的故障类型与已经出现过的特征截然不同。这种情况下我们只需要对负样本进行建模，而非费尽心思对正样本(异常)进行建模。

  正样本比较多，并且具有相似的特征的时候，使用监督学习算法

![image-20220315180516875](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220315180516875.png)

简单来说，正样本足够多的时候可以用监督学习，而正样本非常少的时候则使用异常检测算法

![image-20220315180754499](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220315180754499.png)

## 6. 特征选择

### 非高斯分布

由于我们的异常检测算法是基于假设数据为高斯分布的，尽管当数据为非高斯分布的时候，算法大多数时候依然能够运行，但是在高斯分布的情况下，算法则能够运行地更好。故此时我们可以把非高斯分布转换为高斯分布。根据数据分布特点的不同，可以取对数、(0,1)次幂等等。

![image-20220317130713324](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220317130713324.png)

### 异常检测的误差分析

对于概率模型p(x)来说，我们希望当样本正常的时候，p(x)的取值比较大，而当样本异常的时候取值较小。

然而实际中往往会出现这样的状况：在样本正常和异常的时候，p(x)的取值都比较大。

当出现这种情况的时候，我们就需要给算法增加一个特征$x_2$，使得这个异常样本与正常样本能够在p(x)上分离出来。如下图绿点代表异常样本，红点代表正常样本。

像这样增加特征使得异常样本与正常样本分离的过程，就是异常检测的误差分析。

![image-20220317131727818](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220317131727818.png)

### 例子：监测数据中心的计算机状态

例如在网络服务器中心，我们已经有如下四个特征，但是我们想知道某台计算机是否陷入了死循环(有较高的CPU负载率，但是网络流量较低)，那么我们就可以建立一个新的特征$x_5=\frac{CPU Load}{Network Traffic}$

![image-20220317132407197](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220317132407197.png)

## 7. 多元高斯分布

### 例子：现有分布不足以满足异常检测需求

继续以监测数据中心的计算机状态为例，我们取两个特征：内存使用量和CPU负载。所有的正常样本都用红×表示。我们对两个特征分别进行概率建模，发现它们分别都是高斯分布。并且这两个特征具有一定的线性关系。

这时我们检测到一台异常计算机，具有较高的内存使用和较低的CPU负载，直觉来看显然是一个异常状态。从图中看，绿×代表的这个异常计算机与正常计算机的距离也比较远。然而从两个特征的高斯概率分布图上来看，绿色异常值被混在正常值中，我们无法将它区分为异常值。

事实上对于这种异常检测算法的概率模型来说，绿×代表的样本概率与落在粉色同心圆中相似位置的正常样本概率是类似的(如左图)。

![image-20220317133857267](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220317133857267.png)

### 多元高斯分布

其中一个解决办法是：不要对$x_1、 x_2$分别建模为$p(x_1)、p(x_2)$，而是对二者进行统一建模为$p(x)$。

多元高斯分布的参数为向量u和协方差矩阵$\Sigma$，其分布公式如下

![image-20220317134703925](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220317134703925.png)

### 多元高斯分布的例子

当u为平面原点而$\Sigma$是一个单位矩阵的时候，多元高斯分布的形状如下图左边。这个面的高度就是$p(x)$的值，最高点在原点取得。

当我们把协方差矩阵中的值减小，那么这个圆锥就会变窄，高度会变高，因为这个面以下的体积积分等于1.

当我们把协方差矩阵中的值增大，那么圆锥变宽，高度变矮。

![image-20220317135302983](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220317135302983.png)

假设我们改变第一个特征变量的方差并将它减小，而第二个特征变量的方差不变，那么圆锥截面就会变成椭圆形。

假设增加第一个特征变量的方差，第二个不变，那么依然会变成椭圆形。

![image-20220317135536699](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220317135536699.png)

与之类似：

![image-20220317135609344](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220317135609344.png)

而如果我们改变协方差矩阵的非对角线上的元素，我们会得到一些不同的高斯分布，这两者之间会有一定的相关性(x1 x2一起增加或者一起减小)。当我们把数值增加为0.8的时候，我们看到截面变成很窄的x=y的区域周围。

![image-20220317135921840](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220317135921840.png)

而如果我们把值设为负数，那么图像就会如下，显示出x1和x2之间的负相关关系。

![image-20220317140020226](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220317140020226.png)

改变向量u就会改变截面圆心的位置

![image-20220317140116084](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220317140116084.png)

总体来说，多元高斯分布可以捕捉到当特征之间存在正相关或者负相关关系的情况。

## 8. 使用多元高斯分布的异常检测

### 多元高斯分布的参数估计

多元高斯分布公式：

![image-20220317140957325](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220317140957325.png)

多元高斯分布的参数估计方法

![image-20220317172701964](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220317172701964.png)

### 使用多元高斯分布的异常检测

1. 首先使用上面提到的参数估计方法，将多元高斯分布模型拟合到已有的数据集中，得到多元高斯分布模型

2. 拿到一个新的样本x，根据多元高斯分布公式计算新样本的概率p(X)，并且判断是否有$p(x)< \epsilon$

我们会得到一个有正相关关系的多元高斯分布的等高图(如下图右上)，这样一来就可以正确标记出这个异常样本了。

![image-20220317173246022](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220317173246022.png)

### 与原始模型的关系

当多元高斯分布的模型是轴对齐(axis-aligned)的时候，这个模型也是可以用原始模型去拟合的，如下图

![image-20220317174052153](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220317174052153.png)

这是一种特殊情况下的高斯分布，此时参数$\Sigma$非主对角线上的元素均为0，这意味着不同特征之间不存在相关性。并且，此时的$\Sigma$的对角线上的元素$\sigma_1^2 \cdots \sigma_n^2$对应原始模型中的方差

![image-20220317180509464](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220317180509464.png)

### 原始模型 or 多元高斯模型

原始模型用得更多一点；但多元高斯模型在捕捉特征方面具有一些优势 。

例如，如果我们想捕捉的异常特征是某两种特征组合的结果，如上文提到的CPU和内存问题，那么如果使用原始模型的话，我们就需要新建一个额外的特征，例如$x_3=x_1/x_2$​；而多元高斯模型就能自动捕捉这种不同特征之间的关系。

原始模型的优点是计算成本低，能够适应数量巨大的特征(如n=10000)；而多元高斯模型由于需要计算nxn矩阵$\Sigma$​的逆矩阵，所以计算成本非常高。

原始模型的另一个优点是，可以使用一个较小的训练集数目m去拟合模型p(x)；而对于多元高斯模型来说，m>n是必须的，即样本数量必须大于特征数量，如果不满足这个不等式，则矩阵会变成不可逆的。在实践中，只有m远大于n的时候才选择多元高斯模型。

![image-20220317182536817](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220317182536817.png)

总结来说，原始模型用的更多， 人们会手动增加特征去保证异常值的捕捉；而当n比较小而m又非常大的时候，多元高斯模型可能会运行地更好一些。

另外在运用多元高斯模型的时候还有一点需要注意，当我们发现$\Sigma$是奇异矩阵(不可逆)的时候，有两种可能性：1. 不满足m>n 2. 数据具有冗余特征，例如有2个相同的特征或高度线性相关的特征

