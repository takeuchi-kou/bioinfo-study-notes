![image-20211222094749927](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20211222094749927.png)

# Classical statistics

## 1. main concept

在贝叶斯统计中，我们把未知量$\Theta$视为一个具有先验分布的随机变量。

而在经典统计学中，未知量$\theta$是一个未知常数；

观测值X则是一个随机变量，我们通过对$\theta$条件下的X进行一系列观测，来获得$\theta$的estimator $\hat{\Theta}$，而把具体观测值x带入estimator之后，可以获得估计值$\hat{\theta}$。

$p_X(x;\theta)$并不是一个条件概率，而是对X的概率描述，只不过在概率描述中包含了$\theta$这一未知常数。

所以在进行推断的时候，我们不适用贝叶斯定理，而是把不同的$\theta$可能取值视为一个个不同的模型，而获得观测值之后，我们可以推断这些观测值更有可能来自于哪一个模型。

![image-20211222102305899](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20211222102305899.png)

## 2. problem types

### 类型1：假设检验

在两种备选模型中选择一种模型。

1. 例如：抛掷一枚硬币许多次，猜测这枚硬币是公平1/2的还是偏倚的3/4。

2. 同样是抛掷一枚硬币，猜测这枚硬币是公平的还是不公平的。但此处的不公平包含了许多可能的值

### 类型二：估计问题

未知参数可能是连续或者离散。我们构造一种estimator，使得到的估计值比较准确，也就是估计值与真实值的误差比较小。我们可以对估计值的性能进行度量，但是没有一个最佳标准，不同的人可能会有不同估计方法，但是没有最好的方法。（而在贝叶斯推理中，性能度量的衡量标准是很明确的）

## 3. 估计均值

对于iid r.v. $X_i$来说，均值的estimator $\hat{\Theta}$选择样本均值，并且是一个随机变量而非常量，如图。

一个令人满意的Estimator $\hat{\Theta}$​所具有的性质包括：

- 无偏倚：$E[\hat{\Theta}]$不随着$\theta$取值的变化而发生改变
- 一致性：根据弱大数定理，当n越大时$\hat{\Theta}$越接近$\theta$，且不随着$\theta$取值的变化而发生改变。

在图中的例子里，MSE与$\theta$的取值无关。但是在很多情况下，它的值依赖于$\theta$。

![image-20211222203515204](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20211222203515204.png)

## 4. Estimation error

估计性能的度量可以被MSE(最小均方误差)捕获，它可以通过estimator的方差+估计误差期望的平方求得。

由于在经典统计学框架中，我们对于$\theta$的先验分布没有任何认知，所以无法明确哪种估计方法是最佳的：每种估计方法都有它最贴近真实值的范围——而这个范围我们是不知道的（在贝叶斯框架中我们对$\theta$的先验分布有所了解，所以可以知道哪个估计方法性能最好）。

另外，estimator $\hat{\Theta}$的方差的平方根，又称为标准误差，也是一种用于度量estimator性能的方法。如果其标准误太大，那么可以说明在不同情况下的估计值相差很大，这至少能说明这种估计方法是不精确的（noisy），那么它就不是一个好的estimator。相反如果标准误差很小，则说明这个估计方法在精确度上还不错。

![image-20211222204625386](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20211222204625386.png)

## 5. 置信区间

以民意投票为例。

一个错误的表述是，未知数$\theta$处于置信区间[0.3,0.52]里的概率为95%。

这句话在语义上是不通的，因为未知数$\theta$是一个常数，而不是一个随机变量，对于常数来说，不存在概率问题。

正确的表述应该是，有95%的几率，我们所做的民意调查能够捕获真实值。事实上这个几率指的是构造置信区间的方法，有95%的几率捕获真实参数，而非指的一个实际数值。

![image-20211223125505107](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20211223125505107.png)

### 均值估计的置信区间

$\hat{\Theta}$是i.i.d. r.v. $X_i$的样本均值，也是变量${X_i}$的真实均值的估计值。怎么求出样本均值对真实均值的95%置信区间呢？

首先我们已知$X_i$的分布：均值$\theta$方差$\sigma^2$；

那么根据中心极限定理，我们可以得知$\hat{\Theta}$是一个正态分布的随机变量，其均值为$\theta$​，方差为。

查找标准正态表格，在标准正态随机变量中，97.5%的概率会低于1.96，2.5%的概率低于-1.96，所以在[-1.96,1.96]区间内的概率是95%。

当我们用样本均值减去真实均值，再除以样本均值的标准差，可以得到一个近似标准正态分布，它的绝对值小于1.96的概率是95%。

展开不等式，得到了估计值的置信区间的上界和下界。

观察这个不等式我们可以清楚地看到置信区间的真实含义：估计值有95%的可能性在这个区间内捕获了真实值。

![image-20211223132211219](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20211223132211219.png)

### 方差未知时，求置信区间

方法1：直接取方差可能的最大值。但是这样会使置信区间变大，是一个较为保守的方法。

方法2：用已知信息估计方差。例如伯努利分布中，方差可以通过均值求出，均值又由样本均值估计得到，所以方差的估计值也可以求出。

![image-20211223142455552](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20211223142455552.png)

方法3：一般方法

首先我们知道方差可以写成“与平均数的差的平方的期望值”的形式；

根据弱大数定理，当n越大时，平均数越趋近于期望值；

虽然$\theta$是未知的，但是我们已经对其做出了估计，并且同样当n越大时，$\hat{\Theta}$越接近真值；

因此我们通过$\hat{\Theta}$可以对方差进行估计。

这个过程存在两个近似：

1. 根据中心极限定理，样本均值近似为一个正态分布；
2. 使用估计的$\sigma$值。

但当我们引入了$\sigma$的近似值而非真值时，置信区间应该相应地变宽一些。当n非常大的时候，所有的近似结果都很好，所以无需改变置信区间；而在n比较小。例如30时，我们应该使用t-table而非标准正态分布表格去查询置信区间的范围。

当我们把方差估计值最前面的1/n换成了1/(n-1)，这叫方差的无偏估计值。

![image-20211223171710660](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20211223171710660.png)

## 6. estimator的推广

通过弱大数定理得到X的期望值$\theta=E[X]$​，也就是随机变量X的真实均值，在n趋近于无穷时得到比较好的近似，即样本均值；

推广至任意$\theta=E[g(X)]$，其估计值同样为样本函数均值。

方差的估计是这种推广的一个应用，即$g(X)=(X-\theta_X)$​，依旧按照弱大数定理，就可以得到方差的估计值。

当我们想估计协方差时，只需要把一个随机变量X替换为二维的随机变量$(X_i,Y_i)$，然后按照惯例求估计值即可。

知道方差与协方差的估计值后，可以进一步估计两个变量的相关系数。

![image-20211223175819860](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20211223175819860.png)

## 7. 最大似然估计

在某些情况下，我们并不确定$\theta$是某个随机变量的期望值，此时如何估计$\theta$呢？这时，我们的衡量标准是，使我们已知的数据最有可能发生的$\theta$。

我们可以把最大似然估计法与贝叶斯推理相比较。也就是寻找$\Theta$在随机变量X条件下的后验概率。而此时如果把$\Theta$的先验概率当做是常数的话，贝叶斯公式就与最大似然估计所差无几了。

但是在贝叶斯推理中，我们问的问题是：$\Theta$最有可能的分布/值是什么？

而在最大似然估计中，我们问的问题是：$\theta$等于多少时，能让我的数据最有可能发生？

![image-20211223180814345](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20211223180814345.png)

### ML的一些好用的性质

最大似然估计的estimator也拥有**consistent**的性质，即在n越大的时候越趋近真实值；

同时最大似然法还拥有**渐进正态性**，即我们可以通过把期望值构造成标准正态的方法去构造最大似然估计的estimator（同样会逼近标准正态）；

如果我们要构造标准正态，那么就需要知道estimator的标准误差，在求得标准误后，就可以利用标准正态表格构造置信区间，正如同样本均值的estimator一样。

最大似然估计还拥有渐进有效性，由于这种估计法会制造最小的方差，所以在某种意义上是最佳估计法。

![image-20211223191603991](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20211223191603991.png)

### ML estimation 例1：二项分布

n次抛掷硬币，出现正面的概率为$\theta$，观测值为K。

首先构造最大似然估计的概率公式，即在某个位置参数$\theta$​的条件下K的概率分布，如此一来我们就得到一个正常的二项分布概率公式。

现在要做得是求一个使这个概率公式能得到最大值的$\theta$，换句话说，在$\theta$所有可能的取值中，选择使概率公式结果最大的那个值。

为了简化计算，对公式求对数；然后对公式求导，化简公式得到答案。

值得注意的是，这个答案与之前我们使用贝叶斯方法中的最大后验概率(MAP)方法得到的相同，而在MAP方法中，我们对$\theta$分布没有任何认识，于是假设它为均匀分布。这验证了我们对最大似然估计的理解：对未知参数不具有任何分布上的先验知识。

![image-20211223192436021](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20211223192436021.png)

### ML estimation 例2：正态分布

这次$X_i$是正态分布的iid rv，但是均值和方差都是未知的。

我们可以用公式表示出X的PDF：由于X是独立的，所以其所有取值的joint PDF应该是每个取值概率相乘得到。我们需要最大化这个PDF，同样先取对数在求导。

因为有2个未知参数（均值和方差），所以我们需要分别对这两个未知参数求导，分别求出这两个参数的最佳取值。

经过代数运算，得到了意料中的答案。

![image-20211223193235797](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20211223193235797.png)