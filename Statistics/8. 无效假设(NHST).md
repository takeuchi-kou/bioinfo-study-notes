# 1. overview of NHST

## 1.1 定义

### 无效假设和备择假设

在线性回归的情况下，无效假设指的是回归系数为0；备择假设指的是回归系数大于0.

![image-20220109054905369](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220109054905369.png)

- **directional test**

如果我们对于试验的结果有一个方向性的预测(例如XY的正相关或负相关)，那么则为 directional test；

否则为non-directional test。

- non-directional test 中的假设

无效假设则回归系数为0；备择假设为回归系数不等于0.

![image-20220109055333128](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220109055333128.png)

## 1.2 假设逻辑：p值 、错误、显著性

我们先假设我们的理论是无效的，即null为真，然后进行研究，计算所有的统计数据，然后假定null为真的条件下重新评估该假设。这时获得的概率就是p值。

p值的意义来源于此：在假设null为真的情况下获取我们现在手中数据的概率，如果这种情况下我们获得数据的概率小于5%，那么我们拒绝这个null假设。

![image-20220109055646717](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220109055646717.png)

- I类II类错误

其实是一个混淆矩阵

I类错误：假警报。即我们拒绝了无效假设，然而无效假设其实为真；换句话说，就是试验得到了阳性结果，但是是个假阳性。(例如以为某药物有效但其实无效)

II类错误：miss。即我们接受了无效假设，但其实无效假设为假；换句话说，就是试验得到了假阴性(例如以为某药物无效但其实有效)

![image-20220109060846048](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220109060846048.png)

-  p值的真实意义

不可以反向推断。

先计算无效假设下得到数据的概率，它小于0.05则拒绝无效假设；

而非无效假设为真的概率为0.05

![image-20220109061455416](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220109061455416.png)

- 显著性

如果计算出了p<0.05，就得到了显著性

![image-20220109062502000](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220109062502000.png)

## 1.3 t值

要求p值，首先得求t值

B：回归系数，我们所观察到的回归系数，X对Y的影响程度

SE：标准误差，我们预期中观察到的误差值，即采样误差

![image-20220109062715138](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220109062715138.png)

如果B很高，即X对Y的影响很大，并且SE低，即采样误差很小，我们会得到很高的t值，从而得到很低的p值；

如果B值与观测误差相同，即X对Y的影响，与误差对Y的影响差不多，这说明结果Y很大程度上是由误差造成的，那我们将得到比较高的p值。

## 1.4 summary

![image-20220109064151747](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220109064151747.png)

# 2. controversial of NHST

## 2.1 problems

![image-20220109064320230](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220109064320230.png)

### NHST 受到样本量的影响

由于p值由t值计算得到，而t值的公式分母中有样本量N。那么我们可以知道，在样本量极大的时候，我们一定能得到一个很小的p，无论回归系数如何。

![image-20220109064554170](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220109064554170.png)

### 临界值的选择很随意

cut-off值总是0.05，已经成为标准，但这个标准没有道理。

如果p非常接近0.05，但是并不小于0.05，就会出现一些问题。

![image-20220109064734648](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220109064734648.png)

### 知识匮乏的选择

很多研究者选择NHST只是因为这是他们唯一所知的研究逻辑，而不是他们是个很好的选择。

![image-20220109065115063](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220109065115063.png)

### 错误倾向

- 一类错误

当研究者反复进行一个测试的时候，一类错误的概率会上升，这被称为相关测试(dependent tests)。所以我们需要对多次测试进行更正(FDR，老熟人了)。如果不这么做，一类错误的可能性就会不断升高。

- 二类错误

在采样数目相对于总体来说非常小的时候(例如把全世界人口作为总体),此时抽样误差会非常大，那么SE也会非常大，这意味着我们会错过很多阳性结果

![image-20220109065216217](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220109065216217.png)

### 逻辑不明

我们应该遵循的是先假设null为真，然后分析得到数据的概率，然后拒绝假设

![image-20220109065811175](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220109065811175.png)

但是在现实逻辑下会得到很奇怪的结论。

(用贝叶斯公式推演了一下，主要还是对一类二类错误的接受度的问题，以及表述中对于一类二类错误的包容与否问题)

![image-20220109070116983](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220109070116983.png)

## 2.2 补救措施

- 样本量影响：

在给出NHST报告时，同时给出影响效果估计值。这样一来我们知道显著性的同时，可以得知影响的程度。例如，在回归模型中同时报告回归系数和R方。

![image-20220109083914641](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220109083914641.png)

- 临界值的随意选择：

同样给出影响效果大小的估计值

![image-20220109083940608](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220109083940608.png)

- 知识匮乏：

学习其他形式的假设检验；

考虑添加多个备择假设

![image-20220109084132655](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220109084132655.png)

- 错误倾向

类型一：replicate significant effects

类型二：选择较大的具有代表性的随机样本

![image-20220109084232149](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220109084232149.png)

- 可疑逻辑

记住p值

只报告置信区间

运用贝叶斯推理

![image-20220109084532697](https://gitee.com/joy_thestraydog/typora/raw/master/img/image-20220109084532697.png)

