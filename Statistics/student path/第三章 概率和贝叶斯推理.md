# 第三章 概率和贝叶斯推理

在贝叶斯统计中，我们使用**概率分布**来描述不确定性。

## 离散分布和连续分布

![image-20220213204901932](https://gitee.com/joy_thestraydog/typora1.0/raw/master/image-20220213204901932.png)

对于离散情况，分布函数的值可以解释为概率，因为定义这些分布的离散值的数量是有限的。

然而，对于连续概率分布，任何一个值的概率都为0，因为区间内存在无数个值。因此，连续概率分布的值被解释为密度。要将其转换为概率，我们将密度乘以体积。从数学上讲，这相当于将概率密度函数对measure进行积分。

![image-20220213205826197](https://gitee.com/joy_thestraydog/typora1.0/raw/master/image-20220213205826197.png)

## 边际分布和条件分布

![image-20220213205949673](https://gitee.com/joy_thestraydog/typora1.0/raw/master/image-20220213205949673.png)

在本章中，我们还介绍了边际分布。这些是通过对联合分布进行求和(对于离散变量)或者积分(对于连续变量)得到的。

(离散变量的边际分布是通过相加得到的)

![image-20220213210711781](https://gitee.com/joy_thestraydog/typora1.0/raw/master/image-20220213210711781.png)

(连续变量的边际分布是通过积分得到的)

![image-20220213210955991](https://gitee.com/joy_thestraydog/typora1.0/raw/master/image-20220213210955991.png)

我们还介绍了条件分布，它代表我们在观察系统的一部分之后更新了知识的概率分布。在 3.3.6节 我们描述了如何使用条件概率定律计算这些分布。

![image-20220213211956123](https://gitee.com/joy_thestraydog/typora1.0/raw/master/image-20220213211956123.png)

**在贝叶斯推理中，我们的目标是获得条件概率分布——后验概率——这代表我们在观察数据样本后对参数值的不确定性的概率分布。**

## 独立性

![image-20220213212519259](https://gitee.com/joy_thestraydog/typora1.0/raw/master/image-20220213212519259.png)

在本章中，我们介绍了独立性的概念：**如果知道事件A的发生不影响我们对B发射后能够的信念，则两个事件在统计上是独立的。**

这在统计建模中是一个关键概念，因为独立性意味着我们可以通过简单地将每个单独的数据点的概率相乘来得到数据集的整体概率。

(如果事件C赢和D赢是互相独立的，那么他们的联合分布，也就是两个一起赢，的概率应该等于他们各自的边际分布的乘积，如左下角等式所示)

![image-20220213213217877](https://gitee.com/joy_thestraydog/typora1.0/raw/master/image-20220213213217877.png)

**在贝叶斯统计中，我们广泛使用这个结论来计算一系列不同settings的似然函数(likelihood function)。**

## 中心极限定理

通常来说，我们很难证明对某一个概率模型的特定选择是正确的，特别是对于复杂系统来说。中心极限定理给了我们证明的的机会。

中心极限定理指出，无论我们的数据生成过程是怎样的，样本均值总是表现得似乎它对于足够大的样本量（n > 20或30）来说是正态分布的。这意味着对于所有可以被视为均值的过程，我们都可以使用正态分布作为我们的概率模型。

![image-20220213215002218](https://gitee.com/joy_thestraydog/typora1.0/raw/master/image-20220213215002218.png)